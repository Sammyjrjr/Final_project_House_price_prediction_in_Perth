{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68947663",
   "metadata": {},
   "source": [
    "# 1. Data Review & Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7cbcdf",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b716819b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hard_dependencies, dependency, missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/__init__.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     is_numpy_dev,\n\u001b[1;32m     17\u001b[0m     np_version_under1p19,\n\u001b[1;32m     18\u001b[0m     np_version_under1p20,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     22\u001b[0m     pa_version_under2p0,\n\u001b[1;32m     23\u001b[0m     pa_version_under3p0,\n\u001b[1;32m     24\u001b[0m     pa_version_under4p0,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m PY39 \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m9\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     Appender,\n\u001b[1;32m      3\u001b[0m     Substitution,\n\u001b[1;32m      4\u001b[0m     cache_readonly,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     hash_array,\n\u001b[1;32m      9\u001b[0m     hash_pandas_object,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeprecate\u001b[39m(\n\u001b[1;32m     19\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     20\u001b[0m     alternative: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[[F], F]:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/__init__.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:992\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import math as m\n",
    "import scipy.stats as stats\n",
    "import warnings \n",
    "import statsmodels.api as sm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None) \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ff1a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Perth.csv\")\n",
    "#Quickly look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e844eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "import pandas_profiling as pdp\n",
    "profile = ProfileReport(df, title=\"Price house\", \n",
    "                       minimal=True, progress_bar=False,\n",
    "                       missing_diagrams ={\n",
    "                           \"heatmap\": False,\n",
    "                           \"dendrogram\": False\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d8c4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f1d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I changed capitalization to lowercase and replace two columns\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(\"nearest_sch_dist\", \"distance_nearest_school\")\n",
    "df.columns = df.columns.str.replace(\"nearest_stn_dist\", \"distance_nearest_station\")\n",
    "df.columns = df.columns.str.replace(\"cbd_dist\",\"distance_to_city_center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is multicollinearity in this 3 variables so I dropped\n",
    "\n",
    "df.drop([\"nearest_sch_rank\", \"nearest_sch\",\"nearest_stn\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checked for duplicated values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267fa41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053a885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checked the nans in all the dataset\n",
    "df.isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ffcd8",
   "metadata": {},
   "source": [
    "### After I'm going to replace the NaN values of  build_year because represents almost 10% of my dataset and garage 7.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23e0ce",
   "metadata": {},
   "source": [
    "# Price will be my target value because I want to predict the housing price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5354d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d47b69",
   "metadata": {},
   "source": [
    "### In which suburb have the most houses been sold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573988f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"suburb\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ed59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are clearly evidence that from the last 20 years we have a increase of 850%(7 houses ---->1990 to 5261---> 2020)\n",
    "df[\"date_sold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I changed the datetype to only the year\n",
    "\n",
    "df[\"date_sold\"] = pd.to_datetime(df[\"date_sold\"], errors = \"coerce\")\n",
    "df[\"date_sold\"] = df[\"date_sold\"].apply(lambda x: x.strftime(\"%Y\"))\n",
    "\n",
    "df[\"date_sold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7970389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#And then changed the type to numerical\n",
    "df[\"date_sold\"] =df[\"date_sold\"].astype(\"int64\")\n",
    "df[\"date_sold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa6b92b",
   "metadata": {},
   "source": [
    "### Log-transformation on *build_year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log Transformation on build_year to see if the NaN changes the format to gaussian distribution because now are skew\n",
    "log_build_year=np.log(df[\"build_year\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,5), dpi=100)\n",
    "sns.histplot(x=df[\"build_year\"], kde=True, ax=ax[0])\n",
    "sns.histplot(x=log_build_year, kde=True, ax=ax[1])\n",
    "ax[0].set_title(\"Before Log-transformation\")\n",
    "ax[1].set_title(\"After Log-transformation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1c850",
   "metadata": {},
   "source": [
    "### After the logarithmical transformation the plot doesn't look like Gaussian distribution....\n",
    "### I checked the mean of the logarithmical and is too low (7.6 underfits a lot... when the normal mean is 2003\n",
    "# So I decided to replace the NaN values with the mean of build_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8120f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"build_year\"].fillna((df[\"build_year\"].mean()), inplace = True)\n",
    "df[\"build_year\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2dafa",
   "metadata": {},
   "source": [
    "### Log-transformation on  *Garage*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checked Log Transformation on garage\n",
    "log_garage=np.log(df[\"garage\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,5), dpi=100)\n",
    "sns.histplot(x=df[\"garage\"], kde=True, ax=ax[0])\n",
    "sns.histplot(x=log_garage, kde=True, ax=ax[1])\n",
    "ax[0].set_title('Before Log-transformation')\n",
    "ax[1].set_title('After Log-transformation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d156a",
   "metadata": {},
   "source": [
    "### Log-transformation looks gaussian, So I decided to replace the NaN values with the mean of log_garage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cfef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"garage\"].fillna((log_garage.mean()), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1099e76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Checked the NaNs\n",
    "df.isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I changed it to numerical because if not give me error when I try to substract\n",
    "df[\"build_year\"].astype(\"int64\").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "df[\"house_age\"]= df[\"date_sold\"] - df[\"build_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60c4d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checked numerical values\n",
    "numerical =df.select_dtypes(include=np.number)\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bc468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"date_sold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a19a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Univariate analysis of continuos varaibles\n",
    "for variables in numerical:\n",
    "    plt.figure(figsize=(16,6))\n",
    "    sns.distplot(df, x=df[variables], kde=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe8a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checked categorical values\n",
    "categorical = df.select_dtypes(object)\n",
    "categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004bdb9",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d68fd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation = df.corr()\n",
    "plt.figure(figsize=(22,18))\n",
    "sns_plot =sns.heatmap(correlation, cmap=\"YlGnBu\",annot = True)  \n",
    "figure = sns_plot.get_figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fdd5a",
   "metadata": {},
   "source": [
    "### Visualizing the location of the houses based on latitude and longitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f567dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.jointplot(data=df, x=df[\"latitude\"], y=df[\"longitude\"])\n",
    "plt.ylabel(\"latitude\", fontsize=12) \n",
    "plt.xlabel(\"longitude\", fontsize=12) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc8f11",
   "metadata": {},
   "source": [
    "### The sold houses are higher in longitude between 115-116 and latitude between 31.8-32.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d9c8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"price\", title=\"Distribution of House price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe458e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.box(df, x=\"price\", title=\"Boxplot of House price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.density_contour(df, x=\"price\", y =\"distance_to_city_center\", marginal_x=\"histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c334a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig5 = px.scatter(df, x=df[\"bedrooms\"], y=df[\"price\"],title=\"Price Room\")\n",
    "fig5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2934a86",
   "metadata": {},
   "source": [
    "### With this graph we want to know which is the most common house (Bedroom wise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57fb4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"bedrooms\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"number of Bedroom\")\n",
    "plt.xlabel(\"bedrooms\")\n",
    "plt.ylabel(\"Count\")\n",
    "sns.despine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95120cd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"bedrooms\", title=\"the most common house Bedroom wise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972047c",
   "metadata": {},
   "source": [
    "### The highest seller's are  4 bedroom's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae9a61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.density_contour(df, x=\"price\", y =\"bedrooms\",title=\"Price vs Bedrooms\", marginal_x=\"histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cede32",
   "metadata": {},
   "source": [
    "### there are some irregularaties f.e 10 bedrooms 405k and 2 million per only one bed (a part of this the plot looks trustworthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec2a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3 = px.scatter(df, x=df[\"bedrooms\"], y=df[\"distance_to_city_center\"],title=\"Is the price higher if the city center are near?\")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d9227d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3333 = px.scatter(df, x=df[\"bedrooms\"], y=df[\"distance_nearest_school\"],title=\"Rooms near school\")\n",
    "fig3333.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig234 = px.scatter(df, x=df[\"house_age\"], y=df[\"price\"],title=\"Years\")\n",
    "fig234.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2712e49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig2 = px.scatter(df, x=df[\"price\"], y=df[\"distance_nearest_station\"],title=\"Is the price cheaper near the station?\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78fe53f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig4 = px.scatter(df, x=df[\"price\"], y=df[\"land_area\"],title=\"How much cost the land area?\")\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa273256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig456 = px.scatter(df, x=df[\"price\"], y=df[\"floor_area\"],title=\"price vs floor area\")\n",
    "fig456.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302776db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px.density_contour(df, x=\"price\", y =\"floor_area\", marginal_x=\"histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91a395",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.density_contour(df, x=\"price\", y =\"suburb\", marginal_x=\"histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4119c46",
   "metadata": {},
   "source": [
    "### With this graph we want to check where are the best profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f779a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"suburb\", title=\"Which suburb are more sales?\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234c421",
   "metadata": {},
   "source": [
    "### Which post code has more transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b1584",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"postcode\", title=\"Which post code has more transactions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4532bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"build_year\", title=\"Which year they construct more houses?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c03df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"house_age\", title=\"Age of the house when they sold it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a518f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"date_sold\", title=\"Which year sold more houses?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"garage\", title=\"Number of garages...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7e9e3",
   "metadata": {},
   "source": [
    "### Geomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from arcgis.geocoding import geocode\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "gis = GIS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I got the 1% of my dataset random\n",
    "df2=df.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data\n",
    "df3= pd.DataFrame.spatial.from_xy(df2, \"longitude\",\"latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420cdbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Map of the properties\n",
    "property_map = gis.map(\"Melbourne, perth\")\n",
    "property_map.basemap = \"streets\"\n",
    "property_map \n",
    "#\n",
    "df3.spatial.plot(map_widget=property_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f28fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#See 1% of the sold houses randomly\n",
    "property_map "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91660c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I dropped price because is my target value.\n",
    "# Address and Suburb because are categorical and discrete values\n",
    "X= df.drop([\"price\",\"address\",\"suburb\"], axis=1) \n",
    "y=df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checked the columns\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.32,random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f994533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking number of rows\n",
    "print(\"Nb of rows of X_train = {}\".format(len(X_train)))\n",
    "print(\"Nb of rows of X_test = {}\".format(len(X_test)))\n",
    "print(\"Nb of rows of y_train = {}\".format(len(y_train)))\n",
    "print(\"Nb of rows of y_test = {}\".format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50871e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler3 = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "scaler4 = RobustScaler()\n",
    "ridge = Ridge(alpha=0.3)\n",
    "lasso = Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9945035",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc243dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinReg = reg.fit(X_train, y_train) #training the model\n",
    "\n",
    "# predicting y with X_test\n",
    "y_pred=LinReg.predict(X_test) \n",
    "\n",
    "r2 = r2_score(y_test, y_pred) # calculating r2 \n",
    "mean_sq_err = mean_squared_error(y_test, y_pred) # calculating mean squared error\n",
    "mean_abs_err = mean_absolute_error(y_test, y_pred) # calculating absolute error\n",
    "\n",
    "print(\"The metrics of the basic model are the following:\")\n",
    "print(\"R2 score: \", round(r2,4))\n",
    "print(\"MAE: \", round(mean_abs_err,4))\n",
    "print(\"MSE: \", round(mean_sq_err,4))\n",
    "print(\"RMSE: \", round(np.sqrt(mean_sq_err),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781fa79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the model\n",
    "def model_inplace(scaler, model, X_train, X_test, y_train, y_test):\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    model.fit(X_train,y_train)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mean_sq_err = mean_squared_error(y_test, y_pred) \n",
    "    mean_abs_err = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"R2 score on train set: \", round(model.score(X_train, y_train),4))\n",
    "    print(\"R2 score on test set: \", round(model.score(X_test, y_test),4))\n",
    "    #print(\"MAE: \", round(mean_abs_err,4))\n",
    "    #print(\"MSE: \", round(mean_sq_err,4))\n",
    "    #print(\"RMSE: \", round(np.sqrt(mean_sq_err),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c02b6",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b58200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_inplace(scaler1, reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903721fa",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896ef83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_inplace(scaler2, reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb72e2a",
   "metadata": {},
   "source": [
    "### PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7534227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_inplace(scaler3, reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7488e8d",
   "metadata": {},
   "source": [
    "### RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15997a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_inplace(scaler4, reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the best model using the scaler is PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2631c0c",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4504d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inplace(scaler1, ridge, X_train, X_test, y_train, y_test)#Ridge with Standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inplace(scaler2, ridge, X_train, X_test, y_train, y_test)#Ridge with Minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inplace(scaler3, ridge, X_train, X_test, y_train, y_test)#Ridge with Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd62d81f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_inplace(scaler4, ridge, X_train, X_test, y_train, y_test)#Ridge with Robustscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge with polynomial feature is better than the other scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811d8e9",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2268d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inplace(scaler1, lasso, X_train, X_test, y_train, y_test)#Lasso with Standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc3348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_inplace(scaler2, lasso, X_train, X_test, y_train, y_test)#Lasso with Minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5482f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_inplace(scaler3, lasso, X_train, X_test, y_train, y_test)#Lasso with Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611712e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_inplace(scaler4, lasso, X_train, X_test, y_train, y_test)#Lasso with Robustscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ecf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso with Polynomial feature is better than the other scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae0901",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10,100,1000]\n",
    "\n",
    "# Model with a random forest \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f96767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"R2 score on train set:\", rf.score(X_train, y_train))\n",
    "print(\"R2 score on test set:\", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af947a",
   "metadata": {},
   "source": [
    "### Hyperparametertunning using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfg = RandomForestRegressor() # default is alpha=1.0\n",
    "params = {\"n_estimators\":  np.arange(10,100,30)}\n",
    "grid = GridSearchCV(rfg,  param_grid=params, cv=10, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "#print(\"grid.best_estimator:\", params.score(X_train, y_train))\n",
    "print(\"R2 score on train set:\", best_model.score(X_train, y_train))\n",
    "print(\"R2 score on test set:\", best_model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# np.arange(10,100,100): 10--->40--->70--->100   using 10 Folds-CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ce504",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=0).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53dd688",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 score on train set:\", gbr.score(X_train, y_train))\n",
    "print(\"R2 score on test set:\", gbr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10206a11",
   "metadata": {},
   "source": [
    "### Comparing the best R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e7270",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"R2 score on my baseline model : \", round(r2,4))\n",
    "print(\"R2 score on Randomforest train set:\", rf.score(X_train, y_train))\n",
    "print(\"R2 score on Randomforest test set:\", rf.score(X_test, y_test))\n",
    "print(\"R2 score with Hyperparametertunning train set:\", best_model.score(X_train, y_train))\n",
    "print(\"R2 score with Hyperparametertunning test set:\", best_model.score(X_test, y_test))\n",
    "print(\"R2 score on GradientBoostingRegressor train set:\", gbr.score(X_train, y_train))\n",
    "print(\"R2 score on GradientBoostingRegressor test set:\", gbr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Model and the best 3 models\n",
    "Score = pd.DataFrame({\"Metric\":[\"R2 score Baselinemodel\",\"R2 score on RandomForestRegressor\",\"R2 score on Hyperparametertunning\",\"R2 score on Gradientboosting\"],\n",
    "           \"Train\":[0.5771,rf.score(X_train, y_train),best_model.score(X_train, y_train),gbr.score(X_train, y_train)],\n",
    "           \"Test\":[0,rf.score(X_test, y_test),best_model.score(X_test, y_test),gbr.score(X_test, y_test)]})\n",
    "                   \n",
    "                   \n",
    "Score               \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b02cda7",
   "metadata": {},
   "source": [
    "### Feature importance using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71076f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae85c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking = pd.DataFrame({\n",
    "    \"features\":X_features, \"coefficients\": rf.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a65871",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking = rf.feature_importances_.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39aaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feature_ranking, y = X_features, x = rf.feature_importances_, orientation='h', title = \"Feature Importance using Random Forest Regressor \",\n",
    "            labels = {\"x\":\"Coefficients\",\"y\":\"Features\" })\n",
    "fig.update_layout(barmode=\"stack\",yaxis={\"categoryorder\":\"total ascending\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37135253",
   "metadata": {},
   "source": [
    "### Prediction using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f95e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I created the predictions with the model Random Forest Regressor\n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_test = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checked the size of X_train\n",
    "y_pred_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab2b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checked the size of X_test\n",
    "y_pred_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I created a plot for the Groundtruth and Predictions test\n",
    "\n",
    "#X_train\n",
    "fig, ax = plt.subplots(2,1)\n",
    "sns.scatterplot(x=y_train,y=y_pred_train,ax=ax[0]);\n",
    "ax[0].plot(y_train,y_train, color= \"black\")\n",
    "ax[0].set_xlabel(\"Real Price\")\n",
    "ax[0].set_ylabel(\"Predicted Price\")\n",
    "ax[0].set_title(\"Train Set\")\n",
    "\n",
    "#X_test\n",
    "sns.scatterplot(x=y_test,y=y_pred_test,ax=ax[1]);\n",
    "ax[1].plot(y_test,y_test, color= \"black\")\n",
    "ax[1].set_xlabel(\"Real Price\")\n",
    "ax[1].set_ylabel(\"Predicted Price\")\n",
    "ax[1].set_title(\"Test Set\")\n",
    "plt.tight_layout()\n",
    "\n",
    "ax[0].ticklabel_format(axis=\"x\",style=\"sci\",scilimits=(0,0))\n",
    "ax[0].ticklabel_format(axis=\"y\",style=\"sci\",scilimits=(0,0))\n",
    "ax[1].ticklabel_format(axis=\"x\",style=\"sci\",scilimits=(0,0))\n",
    "ax[1].ticklabel_format(axis=\"y\",style=\"sci\",scilimits=(0,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a734c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I created and check how far away predictions are from real values (looks gaussian distribution)\n",
    "residuals = y_train - y_pred_train\n",
    "sns.distplot(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4cb2f",
   "metadata": {},
   "source": [
    "### Confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ce54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval_proportion(confidence_level):\n",
    "    n = len(df)\n",
    "    p = df[\"price\"].mean()\n",
    "    t = stats.t.ppf(confidence_level + (1-confidence_level)/2, df=n-1)\n",
    "    error = t*df.price.std()/m.sqrt(n)\n",
    "    confidence_interval = [p - error, p+error]\n",
    "    return confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3769be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confidende interval proportion 0.95\n",
    "CI_095= confidence_interval_proportion(0.95)\n",
    "CI_095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1051fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confidence_interval_proportion 0.80\n",
    "CI_08= confidence_interval_proportion(0.80)\n",
    "CI_08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483623f",
   "metadata": {},
   "source": [
    "#### Export of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save clean dataframe to a new .csv file to be used in further analysis\n",
    "df.to_csv(\"Perth_final_project.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
